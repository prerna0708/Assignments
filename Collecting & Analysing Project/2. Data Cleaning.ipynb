{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY-4AGBLaeu9"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln8cha-1aeu-"
   },
   "source": [
    "When using social network data for analysis, some extra steps have to be performed to clean the data. Following are the steps we used to clean our tweets data:\n",
    "1. <b>Remove URL (links)</b> - Tweets contain some links/URLs that we do not require in our topic modeling and sentiment analysis. Therefore, using \"re\" package of python, we removed URLs from the tweets using regular expressions.\n",
    "\n",
    "2. <b>Clean Case Issues in Tweets</b> - Capitalisation of words can be a problem while analyzing tweets as an upper and lower case of the same word will be considered two separate words. To account for this, we converted all the words to lowercase using the .lower() function.\n",
    "\n",
    "3. <b>Remove unnecessary words</b> - Since, stopwords are words that do not have any meaning to them and hence, have been removed from the tweets. Also, tweets scrapped are from climate change topics and are expected to be found in each tweet, hence were deleted from the tweets. We also applied the lemmentization technique on the tweets words which is considered to be much more informative than simple stemming. Apart from word reduction, lemmatization considers a language's full vocabulary to apply a morphological analysis to words. Moreover, digits were also removed from the words.\n",
    "\n",
    "*References* \n",
    "* https://towardsdatascience.com/a-guide-to-cleaning-text-in-python-943356ac86ca\n",
    "* https://www.analyticsvidhya.com/blog/2020/11/text-cleaning-nltk-library/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCZvVJnAaeu_"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VqNfFKKnaevA",
    "outputId": "8dc642e7-4397-4f40-e4b1-b976b4fd05e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sanyaanand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanyaanand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODyJEI69aevD"
   },
   "source": [
    "#### Class created to clean the tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4HmBTrIJaevE"
   },
   "outputs": [],
   "source": [
    "# cleaned data\n",
    "class clean_data():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    # function of removing url\n",
    "    def remove_url(self,txt):\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "    \n",
    "    # function of lowercase and punctuations\n",
    "    def clean_text(self,text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)\n",
    "        text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "    def clean(self):\n",
    "        df = self.data.iloc[:,1:4]\n",
    "        # rename the columns \n",
    "        df = df.rename(columns={'0':'date','1':'id','2':'tweets_text'})\n",
    "        df = df.dropna(axis = 0)\n",
    "        # apply remove url function\n",
    "        df['clean_txt'] = [self.remove_url(i) for i in df['tweets_text']]\n",
    "        # apply clean text function\n",
    "        df['clean_txt'] = [self.clean_text(tweet) for tweet in df['clean_txt']]\n",
    "        # removed stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words_in_tweet = [tweet.split() for tweet in df['clean_txt']]\n",
    "        df['clean_words'] = [[word for word in tweet_words if not word in stop_words] for tweet_words in words_in_tweet]\n",
    "        # remove collection words \n",
    "        collection_words = ['climatechange', 'climate', 'change']\n",
    "        df['clean_words'] = [[w for w in word if not w in collection_words] for word in df['clean_words']]\n",
    "        # Lemmentiser\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        df['clean_words'] = [[wordnet_lemmatizer.lemmatize(word) for word in w]for w in df['clean_words']]\n",
    "        # remove digits from words\n",
    "        df['clean_words'] = [[w.replace('\\d+', '') for w in words] for words in df['clean_words']]\n",
    "        # detokenise the clean words to form a sentence\n",
    "        df['clean_words_text'] = [TreebankWordDetokenizer().detokenize(words) for words in df['clean_words']]\n",
    "        # length of the tweet\n",
    "        df['tweet_length'] = [len(tokens) for tokens in df['clean_txt']]\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoeRjvtQaevE"
   },
   "source": [
    "#### Apply the above created class to clean the tweets dataset and remove uncessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hQFpqqFtaevF"
   },
   "outputs": [],
   "source": [
    "# load tweets data set\n",
    "tweets_data = pd.read_csv('./tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tHbcIfFBaevF"
   },
   "outputs": [],
   "source": [
    "# clean the data\n",
    "tweets = clean_data(tweets_data)\n",
    "data = tweets.clean()\n",
    "# drop unnescessary column\n",
    "data = data.drop('clean_words',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRxoq9lbaevG"
   },
   "source": [
    "#### Overview of cleaned data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BWdgGZLmaevG",
    "outputId": "6a46e3c6-5afa-4bc7-9650-4e7a047d9d24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>clean_words_text</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>2021-05-06 02:45:01</td>\n",
       "      <td>1.390135e+18</td>\n",
       "      <td>The GOP is in climate denial. https://t.co/5rQ...</td>\n",
       "      <td>the gop is in climate denial</td>\n",
       "      <td>gop denial</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>2021-05-06 17:02:48</td>\n",
       "      <td>1.390351e+18</td>\n",
       "      <td>This was passed along from a friend at RBC. He...</td>\n",
       "      <td>this was passed along from a friend at rbc hea...</td>\n",
       "      <td>passed along friend rbc head cftc talking two ...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021-05-06 21:45:29</td>\n",
       "      <td>1.390422e+18</td>\n",
       "      <td>I don’t know if it’s exist but, could you anim...</td>\n",
       "      <td>i dont know if its exist but could you animato...</td>\n",
       "      <td>dont know exist could animator video trophy an...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>2021-05-06 18:34:44</td>\n",
       "      <td>1.390374e+18</td>\n",
       "      <td>#30x30 is an ambitious and necessary endeavor ...</td>\n",
       "      <td>is an ambitious and necessary endeavor to con...</td>\n",
       "      <td>ambitious necessary endeavor conserve nature b...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>2021-05-05 23:27:21</td>\n",
       "      <td>1.390086e+18</td>\n",
       "      <td>*adds elevated maternal death rate for black w...</td>\n",
       "      <td>adds elevated maternal death rate for black wo...</td>\n",
       "      <td>add elevated maternal death rate black woman p...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date            id  \\\n",
       "8458  2021-05-06 02:45:01  1.390135e+18   \n",
       "2713  2021-05-06 17:02:48  1.390351e+18   \n",
       "149   2021-05-06 21:45:29  1.390422e+18   \n",
       "1856  2021-05-06 18:34:44  1.390374e+18   \n",
       "9550  2021-05-05 23:27:21  1.390086e+18   \n",
       "\n",
       "                                            tweets_text  \\\n",
       "8458  The GOP is in climate denial. https://t.co/5rQ...   \n",
       "2713  This was passed along from a friend at RBC. He...   \n",
       "149   I don’t know if it’s exist but, could you anim...   \n",
       "1856  #30x30 is an ambitious and necessary endeavor ...   \n",
       "9550  *adds elevated maternal death rate for black w...   \n",
       "\n",
       "                                              clean_txt  \\\n",
       "8458                       the gop is in climate denial   \n",
       "2713  this was passed along from a friend at rbc hea...   \n",
       "149   i dont know if its exist but could you animato...   \n",
       "1856   is an ambitious and necessary endeavor to con...   \n",
       "9550  adds elevated maternal death rate for black wo...   \n",
       "\n",
       "                                       clean_words_text  tweet_length  \n",
       "8458                                         gop denial            28  \n",
       "2713  passed along friend rbc head cftc talking two ...           174  \n",
       "149   dont know exist could animator video trophy an...           258  \n",
       "1856  ambitious necessary endeavor conserve nature b...           150  \n",
       "9550  add elevated maternal death rate black woman p...           113  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iQlW0KHaevG"
   },
   "source": [
    "#### Save dataset to a csv file to be directly used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GFfz4-ARaevH"
   },
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_data.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2. Data Cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
