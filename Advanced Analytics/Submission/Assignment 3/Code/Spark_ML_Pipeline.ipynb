{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qualified-stuart",
   "metadata": {},
   "source": [
    "# Connect to Spark and Collect Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "determined-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(\"local[*]\",\"PySparkShell\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-wedding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4b89798710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('PySparkShell').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "located-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "retired-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "described-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-round",
   "metadata": {},
   "source": [
    "Save the tweets on local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unknown-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.saveAsTextFiles(\"/home/lukabeverin/Documents/Leuven/Second Semester/Advanced Analytics/Assignment 3/TextData/SavedTexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "proper-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "received-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atlantic-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sc.textFile(\"/home/lukabeverin/Documents/Leuven/Second Semester/Advanced Analytics/Assignment 3/TextData/SavedTexts-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "social-appendix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"tweet_id\": 1392894115793326090, \"tweet_text\": \"@PeterSchiff @qryptoo Are you serious right now? Let me get this straight if your kid tumbles while making his first baby steps you shoot him? #\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588 #\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588 #\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588 #\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588 #\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588\\\\u2588iscoming https://t.co/uds83arn6X\", \"label\": \"#inflation\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sensitive-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "analyzed-easter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+\n",
      "|         label|           tweet_id|          tweet_text|\n",
      "+--------------+-------------------+--------------------+\n",
      "|    #inflation|1392894115793326090|@PeterSchiff @qry...|\n",
      "|      #vaccine|1392894443426963456|@ReallySwara You ...|\n",
      "|      #vaccine|1392894360635707398|PARENTS - What to...|\n",
      "|    #inflation|1392894738995548166|Odds of a lower c...|\n",
      "|    #inflation|1392894448758108160|Strongest #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|\n",
      "|        #biden|1392894964850331648|Brad and Britt Ca...|\n",
      "|        #biden|1392894942943580169|\"#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|\n",
      "|        #biden|1392894911700144134|‚è∞Running OUT‚åõÔ∏è #‚ñà...|\n",
      "|    #inflation|1392895011964997633|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ground s...|\n",
      "|    #inflation|1392895003618385922|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|\n",
      "|    #inflation|1392895225111011329|We all can use so...|\n",
      "|    #inflation|1392895201409175563|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ground s...|\n",
      "|        #covid|1392895857033453571|@TomSwarbrick1 if...|\n",
      "|        #covid|1392895823206359047|Oxygen cylinders ...|\n",
      "|        #covid|1392895789769412608|This #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà...|\n",
      "|#stopasianhate|1392895918890962945|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñàüáµüá∏ #‚ñà‚ñà‚ñà...|\n",
      "|#stopasianhate|1392895867615653891|\"you absolutely d...|\n",
      "|#stopasianhate|1392895866034434049|The audacity of a...|\n",
      "|        #biden|1392896270990069766|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|\n",
      "|        #biden|1392896259242041351|White House moves...|\n",
      "+--------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "immediate-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "restricted-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['tweet_id']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-julian",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "personalized-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "raised-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "underlying-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "#A regex based tokenizer that extracts tokens either by using the provided regex pattern \n",
    "#to split the text (default) or repeatedly matching the regex (if gaps is false). \n",
    "#Optional parameters also allow filtering tokens using a minimal length.\n",
    "#It returns an array of strings that can be empty.\n",
    "\n",
    "\n",
    "#still looking how to remove all mention @\n",
    "#data = data.withColumn('tweet_text', regexp_replace('tweet_text', '/ @*/', ''))\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"tweet_text\", outputCol=\"words\", pattern=\"\\\\W\")# stop words\n",
    "\n",
    "\n",
    "\n",
    "#add custom stop words we want to remove\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)# bag of words count\n",
    "\n",
    "#countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wound-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|     label|          tweet_text|               words|            filtered|         rawFeatures|            features|target|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|#inflation|@PeterSchiff @qry...|[peterschiff, qry...|[peterschiff, qry...|(10000,[125,763,1...|(10000,[125,763,1...|   5.0|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF,idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "dataset.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-namibia",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-camping",
   "metadata": {},
   "source": [
    "Tfidf + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "coated-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 300\n",
      "Test Dataset Count: 105\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-queen",
   "metadata": {},
   "source": [
    "possible parameters: maxIter=20, regParam=0.3, elasticNetParam=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "normal-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"target\",family = \"multinomial\", featuresCol=\"features\")\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thirty-screen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+------+----------+\n",
      "|                    tweet_text|   label|                   probability|target|prediction|\n",
      "+------------------------------+--------+------------------------------+------+----------+\n",
      "|.@g20org @POTUS @SecBlinken...|  #covid|[1.0,4.1961085260023297E-23...|   2.0|       0.0|\n",
      "|LET'S GO T-SHIRT ... Buy No...|  #china|[1.0,3.1776117061691716E-26...|   3.0|       0.0|\n",
      "|Discuss the status of avail...|  #covid|[1.0,9.551039322298131E-27,...|   2.0|       0.0|\n",
      "|Ya boy is going for his fir...|#vaccine|[1.0,4.013308477752283E-31,...|   0.0|       0.0|\n",
      "|Round 1 of Covid vaccine do...|#vaccine|[1.0,1.998305810272253E-33,...|   0.0|       0.0|\n",
      "|That's the way to go for an...|#vaccine|[1.0,1.8687542184506683E-33...|   0.0|       0.0|\n",
      "|It‚Äôs a beautiful day AND ha...|#vaccine|[1.0,3.1127819257209254E-35...|   0.0|       0.0|\n",
      "|I think the people who were...|#vaccine|[1.0,9.340228168335533E-40,...|   0.0|       0.0|\n",
      "|Go get your #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà so we ...|#vaccine|[1.0,1.5652103807550931E-40...|   0.0|       0.0|\n",
      "|Like @POTUS said so many #‚ñà...|#vaccine|[1.0,1.182642145140951E-54,...|   0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"tweet_text\",\"label\",\"probability\",\"target\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "married-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "elementary-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.342857\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-consortium",
   "metadata": {},
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "legendary-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prepared-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.write().overwrite().save(\"/home/lukabeverin/Documents/Leuven/Second Semester/Advanced Analytics/Assignment 3/Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dominican-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = lrModel.load(\"/home/lukabeverin/Documents/Leuven/Second Semester/Advanced Analytics/Assignment 3/Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "otherwise-greece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_31778765de73, numClasses=6, numFeatures=10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-carter",
   "metadata": {},
   "source": [
    "# Make Predictions on Incoming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wanted-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "numeric-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    #transform new incoming data\n",
    "    dataset = pipelineFit.transform(df)\n",
    "\n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = reloaded_model\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model: \n",
    "    df_result = globals()['my_model'].transform(dataset)\n",
    "    df_result = df_result.select(\"label\",\"tweet_id\",\"tweet_text\",\"target\",\"prediction\")\n",
    "    \n",
    "    \n",
    "    df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ranking-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "earned-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mathematical-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2021-05-22 18:02:50 =========\n",
      "+--------+-------------------+--------------------+\n",
      "|   label|           tweet_id|          tweet_text|\n",
      "+--------+-------------------+--------------------+\n",
      "|#vaccine|1396131732777316363|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà passport...|\n",
      "+--------+-------------------+--------------------+\n",
      "\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "|   label|           tweet_id|          tweet_text|target|prediction|\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "|#vaccine|1396131732777316363|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà passport...|   0.0|       4.0|\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "\n",
      "========= 2021-05-22 18:03:00 =========\n",
      "+--------+-------------------+--------------------+\n",
      "|   label|           tweet_id|          tweet_text|\n",
      "+--------+-------------------+--------------------+\n",
      "|#vaccine|1396131648882630659|Why would you get...|\n",
      "+--------+-------------------+--------------------+\n",
      "\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "|   label|           tweet_id|          tweet_text|target|prediction|\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "|#vaccine|1396131648882630659|Why would you get...|   0.0|       0.0|\n",
      "+--------+-------------------+--------------------+------+----------+\n",
      "\n",
      "========= 2021-05-22 18:03:10 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1396132504395001857|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "| label|           tweet_id|          tweet_text|target|prediction|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "|#covid|1396132504395001857|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà #‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà...|   2.0|       5.0|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "\n",
      "========= 2021-05-22 18:03:20 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1396132308025962497|@IndiaTVHindi @in...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "| label|           tweet_id|          tweet_text|target|prediction|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "|#covid|1396132308025962497|@IndiaTVHindi @in...|   2.0|       0.0|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "\n",
      "========= 2021-05-22 18:03:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#biden|1396132905579991041|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Word of ...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "| label|           tweet_id|          tweet_text|target|prediction|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "|#biden|1396132905579991041|#‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Word of ...|   1.0|       5.0|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "antique-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2021-05-22 18:03:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1396133109456834561|On a different no...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "| label|           tweet_id|          tweet_text|target|prediction|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "|#covid|1396133109456834561|On a different no...|   2.0|       2.0|\n",
      "+------+-------------------+--------------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-delta",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-integer",
   "metadata": {},
   "source": [
    "- Convert target and prediction column back into label so it is easier to visualise the performance of the model.\n",
    "- Get more data for training the model\n",
    "- Struggled to preproccess data in Spark ML as effectively as in Pandas(DataFrame)\n",
    "- There are cons to bow and tfidf\n",
    "- Explore word2vec embeddings in the future\n",
    "- CNN in spark ML is challenging\n",
    "- Fantastic skeleton code provided by the Prof\n",
    "- Deploy on Github will be challenging\n",
    "- Could try cv or gridsearch to select best model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-bargain",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-breakdown",
   "metadata": {},
   "source": [
    "- The focus of this assignment is on getting the full pipeline as outlined above constructed, and not on getting spectacularly high accuracies, though TF-IDF, ... might be interesting to apply. We have accomplished this task.\n",
    "- Preferably, your predictive model needs to be build using MLlib (so read documentation and tutorials). Our entire pipeline was built in Spark ML. Sklearn was used to explore the data, get a better understanding of the techniques and to validate models.\n",
    "- Streaming server did not crash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
